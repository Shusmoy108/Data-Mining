{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c5a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Name: Shusmoy Chowdhury\n",
    "\n",
    "Number of Neighbours Selection: validation(validationdata,traindata) function is used to find the neighbours number.\n",
    "I have randomly shuffled the training dataset and divided the training dataset into validation set (20%) and Train set(80%)\n",
    "I will use the validation set to find the number of neighbours.\n",
    "I will start from one for neighbours number and check if the accuracy is more than 90%.\n",
    "If the accuracy is less than 90% then we will increase the neighbours number by one. \n",
    "If the accuracy is more than 90% we will terminate and return the number of neighbours K.  \n",
    "but I have seen that the accuracy is never more than 90%. \n",
    "From Durham's Law we can see that number of neighbours <= square root(training set length)\n",
    "So the validation will end when number of neighbours will exceed square root(training set length)\n",
    "it will return the number of neighbours with maximum accuracy.\n",
    "\n",
    "Output from validation function:\n",
    "\n",
    "k= 1  and accuracy =   85.8%\n",
    "k= 2  and accuracy =   85.8%\n",
    "k= 3  and accuracy =   87.9%\n",
    "k= 4  and accuracy =   88.4%\n",
    "k= 5  and accuracy =   86.8%\n",
    "k= 6  and accuracy =   87.9%\n",
    "k= 7  and accuracy =   86.8%\n",
    "k= 8  and accuracy =   87.4%\n",
    "k= 9  and accuracy =   85.3%\n",
    "k= 10 and accuracy =   84.7%\n",
    "k= 11 and accuracy =   84.7%\n",
    "k= 12 and accuracy =   84.7%\n",
    "k= 13 and accuracy =   83.7%\n",
    "k= 14 and accuracy =   84.2%\n",
    "k= 15 and accuracy =   82.6%\n",
    "k= 16 and accuracy =   81.6%\n",
    "k= 17 and accuracy =   81.6%\n",
    "k= 18 and accuracy =   81.1%\n",
    "k= 19 and accuracy =   80.0%\n",
    "k= 20 and accuracy =   79.5%\n",
    "k= 21 and accuracy =   78.9%\n",
    "k= 22 and accuracy =   80.5%\n",
    "k= 23 and accuracy =   80.5%\n",
    "k= 24 and accuracy =   77.9%\n",
    "k= 25 and accuracy =   77.9%\n",
    "k= 26 and accuracy =   78.9%\n",
    "k= 27 and accuracy =   78.9%\n",
    "\n",
    "number of neighbours k =4\n",
    "\n",
    "Accuracy : 88.0%(k=4)\n",
    "\n",
    "\n",
    "\n",
    "Comments: From my validation function I have got the number of neighbours 4 with maximum accuracy 88.4%. \n",
    "But this produced accuracy 88.0%. So I have tried other values of K (1=10) to check the accuracy.\n",
    "\n",
    "If k=1  then accuracy is 82.0% , Number of missclassified is 9\n",
    "If k=2  then accuracy is 82.0% , Number of missclassified is 9\n",
    "If k=3  then accuracy is 86.0% , Number of missclassified is 7\n",
    "If k=4  then accuracy is 88.0% , Number of missclassified is 6\n",
    "If k=5  then accuracy is 86.0% , Number of missclassified is 7\n",
    "If k=6  then accuracy is 86.0% , Number of missclassified is 7\n",
    "If k=7  then accuracy is 86.0% , Number of missclassified is 7\n",
    "If k=8  then accuracy is 86.0% , Number of missclassified is 7\n",
    "If k=9  then accuracy is 86.0% , Number of missclassified is 7\n",
    "If k=10 then accuracy is 86.0% , Number of missclassified is 7\n",
    "\n",
    "So we can see that k=4 gives us best accuracy with 88%. \n",
    "We can improve the accuracy by using different kind of distance like minkowski distance, manhattan distance, cosine distance etc.\n",
    "We may try with the majority voting instead of weighted voting to improve our accuracy.\n",
    "'''\n",
    "import numpy as np\n",
    "import math\n",
    "# loading the train dataset from csv skiping the first row(label)\n",
    "data = np.loadtxt('MNIST_train.csv',comments='#',delimiter=',',skiprows=1)\n",
    "x = int(len(data)*.8) # spliting the data into 80% and 20% for traing and vallidation\n",
    "# validation data will be used for finding the optimal value k in KNN\n",
    "np.random.shuffle(data)\n",
    "train_data=data[:x,:] # training dataset\n",
    "validation_data=data[x:,:] #validation dataset\n",
    "# loading the test dataset from csv skiping the first row(label)\n",
    "test_data = np.loadtxt('MNIST_test.csv',comments='#',delimiter=',',skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ca9eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the eucledian distance for two data points\n",
    "def eucledianDistance(point1, point2):\n",
    "    dist=0;\n",
    "    #finding the distance for every feature\n",
    "    for i in range (1,len(point1)): #started from 1 as 0 index is the class label\n",
    "        dist= dist + (point1[i]-point2[i])**2 # sum of (point1's ith feature - point2's ith feature)^2 \n",
    "    return math.sqrt(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e25a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the nearest neighbours of the test point in train for KNN\n",
    "#test_point = testdata point which neighbours we want to find\n",
    "#train_data= Training dataset to find neighbours\n",
    "#index= index of already found neighbours so that same neighbours does not repeat\n",
    "def getNeighbours(test_point, train_data, index):\n",
    "    mn=99999\n",
    "    lb=-1\n",
    "    idx=-1\n",
    "    for i in range (len(train_data)):\n",
    "        dist=eucledianDistance(test_point,train_data[i]) # finding the eucledian distance for test_point and i th point in training data\n",
    "        if(mn>dist and (i not in index)): #checking if the distance is minimum and is not already a neighbour\n",
    "            mn=dist #assiining the distance as minimum distance\n",
    "            idx=i # storing the index of the point in training data \n",
    "            lb=train_data[i][0] # storing the label of the minimum distance data point\n",
    "    return [lb,idx,mn] # returning the class label, index of the neighbour in training dataset, and minimum distance between the neighbour and the test point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44627aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-nearest-neighbour classifier\n",
    "#testdata= test dataset/ validation dataset\n",
    "#traindata = train dataset\n",
    "#k = number of neighbours\n",
    "def KNN_classify(testdata,traindata,k):\n",
    "    neighboursLabel=[] # array to store the neighbours label\n",
    "    index=[] # array to store the neighbours index in the train dataset so that same data point in the training dataset is not repeated\n",
    "    neighboursDistance=[] # array to store the distance of the neighbours\n",
    "    for j in range (k): # loop from 0 to number of neighbours\n",
    "        neighbours= getNeighbours(testdata,traindata,index) #getting the neighbours\n",
    "        neighboursLabel.append(int(neighbours[0])) #storing the neighbours class label\n",
    "        index.append(neighbours[1]) # storing the neighbours index in the training dataset\n",
    "        neighboursDistance.append(neighbours[2]) #storing the neighbours distance\n",
    "        vote={} #creating a dictionary to count the vote of the neighbours class label\n",
    "    for i in range(len(neighboursLabel)): # loop from 0 to number of neighbours\n",
    "        if neighboursLabel[i] not in vote.keys(): \n",
    "            vote[neighboursLabel[i]]=0 # if the class label is not in dictionary add it to dictionary and assign the value 0\n",
    "        #vote is inversely proportional to distance. so every time we will add 1/nerighbours distance^2. \n",
    "        #So we need to check if the neighbours distance is 0 because 1/0 will be infinity on that case.\n",
    "        if neighboursDistance[i]!=0: # checking if the distance is zero\n",
    "            vote[neighboursLabel[i]]=vote[neighboursLabel[i]]+(1/(neighboursDistance[i]*neighboursDistance[i])) # calculating the vote. vote = prevvote + (1/neighbours distance^2))\n",
    "    class_label=max(vote, key=vote.get)# getting the class label with maximum vote\n",
    "    if class_label==testdata[0]:\n",
    "        return [class_label , 1] # returning the class label and 1 if the predicted class label matches the orginal class label \n",
    "    else:\n",
    "        return [class_label , 0] # returning the class label and 0 if the predicted class label does not match the orginal class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be84e407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# validation function works with a sample of the training set and find the optimal number of neighbours with high accuracy\n",
    "# validationdata: a random sample from the training set\n",
    "# trainingdata: training data set\n",
    "def validation(validationdata,traindata):\n",
    "    acc=0 # accuracy intializing with 0\n",
    "    k=1 # intializing the number of neighbours with 1\n",
    "    #x=int(len(trainingdata)*0.1)\n",
    "    mx_k=-1\n",
    "    mx_accuracy=-1\n",
    "    while acc<=0.90: #checking if the accuracy is less than or equal 90%\n",
    "        ax=0 # correctly classified data intializing with 0\n",
    "        for i in range(len(validationdata)):\n",
    "            x=KNN_classify(validationdata[i],traindata,k) # running KNN classifier for each data points of validation data\n",
    "            ax=ax+x[1] # adding the 1 if correctly classified other wise 0\n",
    "             #print(ax)\n",
    "        acc=ax/len(validationdata) # updating the accuracy by dividing correctly classified number with total number of validation data set\n",
    "        print(f\"k= {k} and accuracy = {'%6.1lf' %(acc*100)}%\")\n",
    "        if(acc>=mx_accuracy): \n",
    "            mx_accuracy=acc # storing the maximum accuracy\n",
    "            mx_k=k # storing the number of neighbours with maximum accuracy\n",
    "        k=k+1 # increasing the K's value by 1\n",
    "        if(k>math.sqrt(len(traindata))): #according to durham rule number of neighbours<= square root(length of training sample)\n",
    "            break # if k is greater than square root(length of training sample) we will break\n",
    "    return mx_k # returning the number of neighbours with accuracy more than 90% or maximum accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c91a6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation(validation_data,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0f5f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testSample function is used to test the test data on the KNN classifier\n",
    "def testSample(testdata,traindata):\n",
    "    acc=0 # accuracy intializing with 0\n",
    "    k=validation(validation_data,train_data) #finding the number of neighbours from validation function\n",
    "    print(f\"K = {k}\") # showing the number of neighbours\n",
    "    miss=0 # number missclassified elements intializing with 0\n",
    "    for i in range(len(testdata)):\n",
    "        x=KNN_classify(testdata[i],traindata,k)# running KNN classifier for each data points of test data\n",
    "        acc=acc+x[1] # adding the 1 if correctly classified other wise 0\n",
    "        if(x[1]==0):\n",
    "            miss=miss+1 # adding the 1 for miss classified data\n",
    "        print(f\"Desired class: {int(testdata[i][0])}, computed class: {int(x[0])}\") # showing desired class and computed class\n",
    "    #acc=acc/len(testdata)\n",
    "    print(f\"Accuracy rate: {'%6.1lf' % ((acc/len(testdata))*100)}%\") # showing accuracy of knn classfier \n",
    "    print(f\"Number of misclassified test samples: {miss}\")  # showing number of miss classified   \n",
    "    print(f\"Total number of test samples: {len(testdata)}\") # showing number of total number of test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2665876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 4\n",
      "Desired class: 0, computed Class: 0\n",
      "Desired class: 0, computed Class: 0\n",
      "Desired class: 0, computed Class: 0\n",
      "Desired class: 0, computed Class: 0\n",
      "Desired class: 0, computed Class: 0\n",
      "Desired class: 1, computed Class: 1\n",
      "Desired class: 1, computed Class: 1\n",
      "Desired class: 1, computed Class: 1\n",
      "Desired class: 1, computed Class: 1\n",
      "Desired class: 1, computed Class: 1\n",
      "Desired class: 2, computed Class: 8\n",
      "Desired class: 2, computed Class: 2\n",
      "Desired class: 2, computed Class: 2\n",
      "Desired class: 2, computed Class: 7\n",
      "Desired class: 2, computed Class: 2\n",
      "Desired class: 3, computed Class: 7\n",
      "Desired class: 3, computed Class: 3\n",
      "Desired class: 3, computed Class: 3\n",
      "Desired class: 3, computed Class: 3\n",
      "Desired class: 3, computed Class: 3\n",
      "Desired class: 4, computed Class: 4\n",
      "Desired class: 4, computed Class: 4\n",
      "Desired class: 4, computed Class: 4\n",
      "Desired class: 4, computed Class: 4\n",
      "Desired class: 4, computed Class: 9\n",
      "Desired class: 5, computed Class: 5\n",
      "Desired class: 5, computed Class: 6\n",
      "Desired class: 5, computed Class: 5\n",
      "Desired class: 5, computed Class: 5\n",
      "Desired class: 5, computed Class: 5\n",
      "Desired class: 6, computed Class: 6\n",
      "Desired class: 6, computed Class: 6\n",
      "Desired class: 6, computed Class: 6\n",
      "Desired class: 6, computed Class: 6\n",
      "Desired class: 6, computed Class: 6\n",
      "Desired class: 7, computed Class: 7\n",
      "Desired class: 7, computed Class: 7\n",
      "Desired class: 7, computed Class: 7\n",
      "Desired class: 7, computed Class: 7\n",
      "Desired class: 7, computed Class: 7\n",
      "Desired class: 8, computed Class: 8\n",
      "Desired class: 8, computed Class: 8\n",
      "Desired class: 8, computed Class: 8\n",
      "Desired class: 8, computed Class: 8\n",
      "Desired class: 8, computed Class: 8\n",
      "Desired class: 9, computed Class: 9\n",
      "Desired class: 9, computed Class: 7\n",
      "Desired class: 9, computed Class: 9\n",
      "Desired class: 9, computed Class: 9\n",
      "Desired class: 9, computed Class: 9\n",
      "Accuracy rate:   88.0%\n",
      "Number of misclassified test samples: 6\n",
      "Total number of test samples: 50\n"
     ]
    }
   ],
   "source": [
    "testSample(test_data,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee642dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0db38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33e652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
